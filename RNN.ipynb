{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOkHAIGg/yHh9ns9i8JCmAO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MikolajKita/Neural-Networks/blob/main/RNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "de1x7yb8cdrg",
        "outputId": "72af27b7-6cc4-4830-c16c-c2824c5dbe63"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  p4.zip\n",
            "  inflating: test_no_target.pkl      \n",
            "  inflating: train.pkl               \n",
            "  inflating: treШЖ_zadania.txt     \n"
          ]
        }
      ],
      "source": [
        "!unzip p4.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import DataLoader"
      ],
      "metadata": {
        "id": "b--y4WmFFPOT"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "\n",
        "with open('train.pkl', 'rb') as f:\n",
        "    dataset = pickle.load(f)"
      ],
      "metadata": {
        "id": "1dPve9e8c6Re"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda') # \n",
        "#device = torch.device('cpu')\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yBWLArJiTtUk",
        "outputId": "7806ff54-68e4-4ee3-dbb3-44327f57b760"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "if torch.cuda.is_available(): \n",
        "    torch.cuda.manual_seed(42)\n",
        "    torch.cuda.manual_seed_all(42)\n",
        "    \n",
        "# Additionally, some operations on a GPU are implemented stochastic for efficiency\n",
        "# We want to ensure that all operations are deterministic on GPU (if used) for reproducibility\n",
        "torch.backends.cudnn.determinstic = True\n",
        "torch.backends.cudnn.benchmark = False"
      ],
      "metadata": {
        "id": "LOoSvHiw2XeY"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.set_default_dtype(torch.float64)"
      ],
      "metadata": {
        "id": "GPv4tWIZdAIo"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kTYqSSjwfM-q",
        "outputId": "230e6ca3-204b-41b6-facc-21674aee5941"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uKgNeiouhdNB",
        "outputId": "96d377ed-6b7b-443c-a7eb-ed62595b0d82"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2939"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[642][1]\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T5VP2j3Rfhnq",
        "outputId": "abe69595-9e93-4644-b1b7-641b21555813"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#{0: 'bach', 1: 'beethoven', 2: 'debussy', 3: 'scarlatti', 4: 'victoria'}.\n",
        "\n",
        "class_bach_0 = 0\n",
        "class_beethoven_1 = 0\n",
        "class_debussy_2 = 0\n",
        "class_scarlatti_3 = 0\n",
        "class_victoria_4 = 0\n"
      ],
      "metadata": {
        "id": "aL33wak9hrLt"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range (0,len(dataset)):\n",
        "  if(dataset[i][1] == 0):\n",
        "    class_bach_0 += 1\n",
        "  if(dataset[i][1] == 1):\n",
        "    class_beethoven_1 += 1\n",
        "  if(dataset[i][1] == 2):\n",
        "    class_debussy_2 += 1\n",
        "  if(dataset[i][1] == 3):\n",
        "    class_scarlatti_3 += 1\n",
        "  if(dataset[i][1] == 4):\n",
        "    class_victoria_4 += 1"
      ],
      "metadata": {
        "id": "Hwn-ZQJMhUUR"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_bach_0\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CgH5YZZUi1px",
        "outputId": "3e5ed431-c181-44e0-ee3e-efe63a65a443"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1630"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class_beethoven_1\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GyrjeRQLi8Z_",
        "outputId": "d069e180-362a-45d5-fe06-be31bb7ae331"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "478"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class_debussy_2\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GqfOlE35i-oW",
        "outputId": "fd8977df-34bb-4c56-c5a8-d51de6317563"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "154"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class_scarlatti_3\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5uU1OPtgjBN0",
        "outputId": "bd0066e0-be37-4d43-ac4e-8d6a1199728b"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "441"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class_victoria_4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pAYCC1MAjCUB",
        "outputId": "fa42bb6f-1076-47a1-ba78-f7d4c36710fd"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "236"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "class VariableLenDataset(Dataset):\n",
        "    def __init__(self, in_data):\n",
        "        self.data = [(x, y) for x, y in in_data]    \n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def max(self):\n",
        "        max = 0\n",
        "        for data, target in self.data:\n",
        "            if(len(data) > max):\n",
        "              max = len(data)\n",
        "        return max\n",
        "          \n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        seq, target = self.data[idx]\n",
        "        return seq, target"
      ],
      "metadata": {
        "id": "0eww5L0ulHY2"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_part = int(0.8 * len(dataset))\n",
        "train_size = int(0.8 * train_part)\n",
        "validation_size = train_part - train_size\n",
        "test_size = len(dataset) - train_part\n",
        "train_set, validation_set, test_set = torch.utils.data.random_split(dataset, [train_size, validation_size, test_size])"
      ],
      "metadata": {
        "id": "cBllHadAVDa3"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
        "def collate_fn(batch, pad_value=0):\n",
        "    \"\"\"\n",
        "       data: is a list of tuples with (example, label, length)\n",
        "             where 'example' is a tensor of arbitrary shape\n",
        "             and label/length are scalars\n",
        "    \"\"\"\n",
        "    #print(batch[1])\n",
        "    #inputs = [torch.tensor(d['tokenized_input']) for d in data] #(3)\n",
        "   # labels = [d['label'] for d in data]\n",
        "    seq, target = zip(*batch)\n",
        "    inputs = [torch.tensor(x) for x in seq] #(3)\n",
        "    labels = torch.tensor(target)\n",
        "    seq_pad = pad_sequence(inputs, batch_first=True)\n",
        "    return seq_pad, labels"
      ],
      "metadata": {
        "id": "CupO78H_utNF"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(train_set, batch_size=50, shuffle=True, drop_last = True, collate_fn=collate_fn)\n",
        "test_loader = DataLoader(test_set, batch_size=50, shuffle=False, drop_last = True, collate_fn=collate_fn)\n",
        "validation_loader = DataLoader(validation_set, batch_size=50, shuffle=False, drop_last = True, collate_fn=collate_fn)"
      ],
      "metadata": {
        "id": "xk-C73Usrzbo"
      },
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_set)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zrPI8gwAqa8A",
        "outputId": "6182b99f-cd62-4842-f9df-25937d2d595c"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1880"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(validation_set)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YVL8op_6q4V2",
        "outputId": "26dc6eef-dcdb-46b3-eb76-2f39ecb8e941"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "471"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(test_set)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5bK7G2duVSiS",
        "outputId": "ad940341-bf00-4480-84ff-7ac4108274c9"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "588"
            ]
          },
          "metadata": {},
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_set[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E3mWIzK3HeGd",
        "outputId": "91f4efe1-c2e7-4c86-8bfe-d6663534e14c"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([ 73.,  73.,  80.,  80.,   2.,  80.,  80.,  36.,  92.,  93.,  47.,\n",
              "         88.,  88.,  92., 153.,  47., 180.,  73.,   2., 114.,  88.,   0.,\n",
              "        100., 153.,  80., 168., 158., 175.,  13.,  92.,  92.,   5.,  92.,\n",
              "         47.,  73.,  88.,  88.,  92., 153.,  47., 180.,  47., 172.,  73.,\n",
              "         78.,  60., 185., 185., 185.,   8.,  12., 117., 159., 185., 185.,\n",
              "         98.,   0.,   8.,   8.,  73., 117.,   0.,  36.,  78.,  36.,  36.,\n",
              "         47.,  12.,  12.,  47.,  12., 185.,  12.,  47.,  30.,  44.,  78.,\n",
              "         78.,  44.,  44.,  30.,  30.,  44.,  44.,  44.,  60.,  60.,  60.,\n",
              "         44.,  30.,  25.,  20.,  79.,  79., 185., 185.,  12.,  73.,  73.,\n",
              "         92.,   5.,   5.,  93.,  61., 140., 109.,  79.,  79.,  79., 112.,\n",
              "        146., 120.,  32.,  37.,  37.,   9.,   9., 148., 114., 140.,  60.,\n",
              "        158., 140., 172.,  79.,  79., 159.,  12., 159., 159.,  80., 159.,\n",
              "         28., 156., 111., 137., 137.,  45., 159.,  92.,  33.,  41.,  12.,\n",
              "        159., 125.,   8.,   0., 158., 140., 175., 127., 140., 172.,  73.,\n",
              "        127., 175., 175.,  92., 168.,  92.,  13.,  93., 158.,  47.,  73.,\n",
              "          2., 114.,  88.,   5., 154.,  47.,  92.,  88.,  92., 153.,  47.,\n",
              "         42.,  79.,  79., 120., 120.,  60.,  37.,  79.,  74., 111., 111.,\n",
              "        152., 152.,  92.,   8., 111.,  77.,  12., 159.,  28.,  47., 172.,\n",
              "        190., 190., 125.,  47.,   0.,  47.,  28., 185., 125.,  13.,  60.,\n",
              "         45., 190., 156., 156., 137., 111.,  64.,  66., 152., 152.,   8.,\n",
              "          8.,  92.,  92.,  73.,  47.,  93., 121.,  47., 157., 172.,  92.,\n",
              "        153.,  47.,  47.,   9.,  92.,  92.,  93.,  73.,   0.,   2.,  88.,\n",
              "         88.,   5., 153.,  80., 116., 168., 116., 116.,  92.,  13.,  93.,\n",
              "         13.,  47.,  21.,  80.,  80.,  80.,  80.,   2.,  80.,  80.,  80.,\n",
              "         80.,  80.,  80.]), 3)"
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_features, train_labels = next(iter(train_loader))"
      ],
      "metadata": {
        "id": "LgrOK_VzcAbb"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_features[0].size()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AZQ9vMJ2I8xN",
        "outputId": "1c0d606d-0454-4792-8069-416fc798dc4d"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2645])"
            ]
          },
          "metadata": {},
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_features[1].size()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qWvOxnubJIgU",
        "outputId": "1f62c495-26ae-471a-afe4-68b945ccbe5d"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2645])"
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTMRegressor(nn.Module):\n",
        "\n",
        "    def __init__(self, input_size, hidden_size, num_layers, out_size):\n",
        "        super().__init__()\n",
        "        self.num_layers = num_layers\n",
        "        self.hidden_size = hidden_size\n",
        "        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers)\n",
        "        self.fc = nn.Linear(hidden_size, out_size)\n",
        "        \n",
        "    def init_hidden(self, batch_size):\n",
        "        hidden = torch.zeros(self.num_layers, batch_size, self.hidden_size)\n",
        "        state = torch.zeros(self.num_layers, batch_size, self.hidden_size)\n",
        "        return hidden, state\n",
        "    \n",
        "    def forward(self, x, hidden):\n",
        "        x = torch.transpose(x, 0, 1)\n",
        "        all_outputs, hidden = self.lstm(x, hidden)\n",
        "        out = all_outputs[-1] # We are interested only in the last output\n",
        "        x = self.fc(out)\n",
        "        return x, hidden\n",
        "    \n",
        "model = LSTMRegressor(input_size=1, hidden_size = 100, num_layers = 6, out_size = 5).to(device)\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YVGv0qHQUItx",
        "outputId": "bb972a81-4d78-4c28-8178-19fbad143d62"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LSTMRegressor(\n",
              "  (lstm): LSTM(1, 100, num_layers=6)\n",
              "  (fc): Linear(in_features=100, out_features=5, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "loss_fun = nn.CrossEntropyLoss()\n",
        "\n",
        "training_loss = 0\n",
        "validation_loss = 0\n",
        "num_epochs = 20\n",
        "training_loss = 0\n",
        "validation_loss = 0\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "      #print(i, data)\n",
        "      #print(i, data)\n",
        "\n",
        "      inputs, labels = data\n",
        "      inputs = inputs.to(device).unsqueeze(2)\n",
        "      #inputs = [seq.to(device) for seq in inputs]\n",
        "      labels = labels.to(device)\n",
        "      #print(inputs)\n",
        "      hidden, state = model.init_hidden(inputs.size(0))\n",
        "      hidden, state = hidden.to(device), state.to(device)\n",
        "      preds, last_hidden = model(inputs, (hidden,state))\n",
        "      optimizer.zero_grad() \n",
        "      loss = loss_fun(preds, labels)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      training_loss += loss.item()\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "      for i, data in enumerate(validation_loader, 0):\n",
        "        inputs, labels = data\n",
        "        inputs = inputs.to(device).unsqueeze(2)\n",
        "        labels = labels.to(device)\n",
        "        #hidden, state = hidden.to(device), state.to(device)\n",
        "        preds, last_hidden = model(inputs, (hidden,state))\n",
        "        loss = loss_fun(preds, labels)\n",
        "      \n",
        "        validation_loss += loss.item()\n",
        "\n",
        "    if epoch % 5 == 0:\n",
        "      print(f\"Epoch: {epoch}, training loss: {training_loss/1:.3}, validation loss: {validation_loss/1:.3}\")\n",
        "      training_loss = 0\n",
        "      validation_loss = 0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GCOKIvDnUhVv",
        "outputId": "bea7a1cb-b415-4f08-a6d8-4e77764691e4"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0, training loss: 49.7, validation loss: 11.5\n",
            "Epoch: 5, training loss: 2.37e+02, validation loss: 57.4\n",
            "Epoch: 10, training loss: 2.33e+02, validation loss: 57.2\n",
            "Epoch: 15, training loss: 2.34e+02, validation loss: 57.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "correct_pred = {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}\n",
        "total_pred = {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}\n",
        "correct_pred.items()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g-76bXTKhFWL",
        "outputId": "b6fb0c4e-52e7-4175-b6ae-08ddc94d7c84"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_items([(0, 0), (1, 0), (2, 0), (3, 0), (4, 0)])"
            ]
          },
          "metadata": {},
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "acc_sum = 0\n",
        "with torch.no_grad():\n",
        "    for i, data in enumerate(test_loader, 0):\n",
        "        inputs, labels = data\n",
        "        inputs = inputs.to(device).unsqueeze(2)\n",
        "        labels = labels.to(device)\n",
        "        #hidden, state = hidden.to(device), state.to(device)\n",
        "        preds, last_hidden = model(inputs, (hidden,state))\n",
        "        _, predictions = torch.max(preds, 1)\n",
        "        for label, prediction in zip(labels, predictions):\n",
        "          if label == prediction:\n",
        "              correct_pred[label.item()] += 1\n",
        "          total_pred[label.item()] += 1\n",
        "\n"
      ],
      "metadata": {
        "id": "ygsyx9cHRlWl"
      },
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "correct_pred.items()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZovO2YQZiEFm",
        "outputId": "37293948-a400-47a6-de04-8faede88b01c"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_items([(0, 306), (1, 0), (2, 0), (3, 0), (4, 0)])"
            ]
          },
          "metadata": {},
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total_pred.items()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oMezW3SEiHQ-",
        "outputId": "55931224-e46d-4291-a3f2-2e9ff4e2aa96"
      },
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_items([(0, 306), (1, 87), (2, 28), (3, 84), (4, 45)])"
            ]
          },
          "metadata": {},
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "acc_sum = 0\n",
        "for classname, correct_count in correct_pred.items():\n",
        "    print(\"Class: {}, correct predictions: {}, total_predictions {}\".format(classname, correct_count, total_pred[classname]))\n",
        "    accuracy = 100 * float(correct_count) / total_pred[classname]\n",
        "    acc_sum += accuracy\n",
        "    print(\"Accuracy for class {} is: {:.1f} %\".format(classname, \n",
        "                                                   accuracy))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OSpH9xo_hzcd",
        "outputId": "7df9c216-1cf8-41a8-a36e-a8283e8267eb"
      },
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class: 0, correct predictions: 306, total_predictions 306\n",
            "Accuracy for class 0 is: 100.0 %\n",
            "Class: 1, correct predictions: 0, total_predictions 87\n",
            "Accuracy for class 1 is: 0.0 %\n",
            "Class: 2, correct predictions: 0, total_predictions 28\n",
            "Accuracy for class 2 is: 0.0 %\n",
            "Class: 3, correct predictions: 0, total_predictions 84\n",
            "Accuracy for class 3 is: 0.0 %\n",
            "Class: 4, correct predictions: 0, total_predictions 45\n",
            "Accuracy for class 4 is: 0.0 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "acc_sum"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pOOxBipmjAUi",
        "outputId": "bc6494ad-11d0-4d40-d013-a851c3b6cc42"
      },
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100.0"
            ]
          },
          "metadata": {},
          "execution_count": 141
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "acc_average_all_classes = acc_sum / len(correct_pred)\n",
        "acc_average_all_classes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vmL_kvuVitA0",
        "outputId": "b21b2da3-6d6e-436f-a43e-684bbac7257b"
      },
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20.0"
            ]
          },
          "metadata": {},
          "execution_count": 143
        }
      ]
    }
  ]
}