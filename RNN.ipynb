{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPag0rikKnkIubm6aSXTqvM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MikolajKita/Neural-Networks/blob/main/RNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "de1x7yb8cdrg",
        "outputId": "23366a55-1ed4-4605-fad6-e508210cdc15"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  p4.zip\n",
            "  inflating: test_no_target.pkl      \n",
            "  inflating: train.pkl               \n",
            "  inflating: treШЖ_zadania.txt     \n"
          ]
        }
      ],
      "source": [
        "!unzip p4.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import DataLoader"
      ],
      "metadata": {
        "id": "b--y4WmFFPOT"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "\n",
        "with open('train.pkl', 'rb') as f:\n",
        "    dataset = pickle.load(f)"
      ],
      "metadata": {
        "id": "1dPve9e8c6Re"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda') # \n",
        "#device = torch.device('cpu')\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yBWLArJiTtUk",
        "outputId": "41854221-3a3c-4b81-fab8-d203a104a134"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "if torch.cuda.is_available(): \n",
        "    torch.cuda.manual_seed(42)\n",
        "    torch.cuda.manual_seed_all(42)\n",
        "    \n",
        "# Additionally, some operations on a GPU are implemented stochastic for efficiency\n",
        "# We want to ensure that all operations are deterministic on GPU (if used) for reproducibility\n",
        "torch.backends.cudnn.determinstic = True\n",
        "torch.backends.cudnn.benchmark = False"
      ],
      "metadata": {
        "id": "LOoSvHiw2XeY"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.set_default_dtype(torch.float64)"
      ],
      "metadata": {
        "id": "GPv4tWIZdAIo"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kTYqSSjwfM-q",
        "outputId": "1d5088a6-4b39-4b92-d087-9c4c25bf176b"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[642]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KirVVUA6hDmI",
        "outputId": "ae77c3f5-fe2d-4bea-bddc-437401c5e471"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([ -1.,  -1., 145.,   5.,  88.,  13.,  47.,  47.,  12., 112.,  37.,\n",
              "        132.,  12.,  77.,  92., 156.,  12., 152.,  92.,  12.,  47.,  13.,\n",
              "         47.,  47.,  12.,  78., 119.,  78.,  12.,   8.,  88.,  47.,  78.,\n",
              "         12.,  92.,   5.,  88.,  13.,  47.,  47.,  12., 112.,  37., 132.,\n",
              "         12.,  77.,  92., 156.,  12., 152.,  92.,  12.,  47.,  13.,  47.,\n",
              "         47.,  12.,  78., 119.,  78.,  12.,   8.,  88.,  47.,  78., 131.,\n",
              "          5.,  76.,  79.,  12., 159., 185., 124.,  32.,  39., 190.,  12.,\n",
              "        159., 124., 124., 124.,  79.,  76.,  12.,  44., 157.,  44.,  40.,\n",
              "         44.,  88.,  30.,  88.,  88., 172.,  92.,  44., 191., 172., 172.,\n",
              "        158.,  60., 120.,  60.,  37.,  37.,  60.,  60.,  20.,  60.,  60.,\n",
              "         60.,  44.,  44.,  33.,  33.,  47.,  12., 172.,  92.,  78.,  12.,\n",
              "         69.,  92.,  12.,  69., 159.,  47., 172., 152.,  74.,  12., 159.,\n",
              "          0.,  47.,  47.,  47.,  73., 114., 159., 132., 125.,  78.,  12.,\n",
              "         13.,  12., 152.,  12.,  12.,  92.,  13.,  47.,  47.,  12.,  78.,\n",
              "        156., 156.,  13., 145.,  92.,  64., 152., 144.,   5.,  76.,  79.,\n",
              "         12., 159., 185., 124.,  32.,  39., 190.,  12., 159., 124., 124.,\n",
              "        124.,  79.,  76.,  12.,  44., 157.,  44.,  40.,  44.,  88.,  30.,\n",
              "         88.,  88., 172.,  92.,  44., 191.,  46., 172., 158.,  60., 120.,\n",
              "         60.,  37.,  37.,  60.,  60.,  60., 127.,  60.,  60.,  44.,  44.,\n",
              "         33.,  33.,  47.,  12., 172.,  92.,  78.,  12.,  69.,  92.,  12.,\n",
              "         69., 159.,  47., 172., 152.,  74.,  12., 159.,   0.,  47.,  47.,\n",
              "         47.,  73., 114., 159., 132., 125.,  78.,  12.,  13.,  12., 152.,\n",
              "         12.,  12.,  92.,  13.,  47.,  47.,  12.,  78., 156., 156.,  13.,\n",
              "        145.,  92.,  64., 152., 144., 144., 144.,  30., 191.,  40.,  40.,\n",
              "         25., 132., 132., 132., 156.,  37.,  25.,  37.,  34.,  40.,  40.,\n",
              "        144.,  30., 191.,  40.,  40.,  25.,  77.,  30., 132.,  32., 105.,\n",
              "        100.,  37.,  34., 144.,  40., 144.,  30., 191.,  40.,  40.,  25.,\n",
              "        132., 132., 132., 156.,  37.,  25.,  37.,  34.,  40.,  40., 144.,\n",
              "         30., 191.,  40.,  40.,  25.,  77.,  30., 132.,  32., 105., 100.,\n",
              "         37.,  34.,  66., 144., 144., 149.,  44., 149.,  40.,  40., 146.,\n",
              "         32., 146.,  79., 110.,  44.,  37.,  32., 146., 132., 132., 132.,\n",
              "         25.,  44.,  40.,  25.,  84.,  25.,  40.,  44.,  25.,  25., 105.,\n",
              "        152.,  37., 156., 144.,  30., 191.,  40.,  40.,  25., 132., 132.,\n",
              "        132., 156.,  37.,  25.,  37.,  40.,  30.,  30., 144.,  30.,  30.,\n",
              "         40., 132.,  74.,  58.,  44.,  74.,  31.,  37., 111., 111., 144.,\n",
              "         66., 144., 144., 149.,  44., 149.,  40.,  40., 146.,  32., 146.,\n",
              "         79., 110.,  44.,  37.,  32., 146., 132., 132., 132.,  25.,  44.,\n",
              "         40.,  25.,  84.,  25.,  40.,  44.,  25.,  25., 105., 152.,  37.,\n",
              "        156., 144.,  30., 191.,  40.,  40.,  25., 132., 132., 132., 156.,\n",
              "         37.,  25.,  37.,  40.,  30.,  30., 144.,  30.,  30.,  40., 132.,\n",
              "         74.,  58.,  44.,  74.,  31.,  37., 111., 111., 144., 144.,  24.,\n",
              "          5.,  88.,  13.,  47.,  47.,  12., 112.,  37., 132.,  12.,  77.,\n",
              "         92., 156.,  12., 152.,  92.,  12.,  47.,  13.,  47.,  47.,  12.,\n",
              "         78., 119.,  78.,  12.,   8.,  88.,  47.,  78., 131.,   5.,  76.,\n",
              "         79.,  12., 159., 185., 124.,  32.,  39., 190.,  12., 159., 124.,\n",
              "        124., 124.,  79.,  76.,  12.,  44., 157.,  44.,  40.,  44.,  88.,\n",
              "         30.,  88.,  88., 172.,  92.,  44., 191.,  46., 172., 158.,  60.,\n",
              "        120.,  60.,  37.,  37.,  60.,  60.,  60., 127.,  60.,  60.,  44.,\n",
              "         44.,  33.,  33.,  47.,  12., 172.,  92.,  78.,  12.,  69.,  92.,\n",
              "         12.,  69., 159.,  47., 172., 152.,  74.,  12., 159.,   0.,  47.,\n",
              "         47.,  47.,  73., 114., 159., 132., 125.,  78.,  12.,  13.,  12.,\n",
              "        152.,  12.,  12.,  92.,  13.,  47.,  47.,  12.,  78., 156., 156.,\n",
              "         13., 145.,  92.,  64., 152., 144., 144.,  -1.]), 0)"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uKgNeiouhdNB",
        "outputId": "c39746a9-019a-4a8d-ef0f-b39da6dffbf8"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2939"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[642][1]\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T5VP2j3Rfhnq",
        "outputId": "322d0ca1-d9a1-41aa-b426-07949022f498"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#{0: 'bach', 1: 'beethoven', 2: 'debussy', 3: 'scarlatti', 4: 'victoria'}.\n",
        "\n",
        "class_bach_0 = 0\n",
        "class_beethoven_1 = 0\n",
        "class_debussy_2 = 0\n",
        "class_scarlatti_3 = 0\n",
        "class_victoria_4 = 0\n"
      ],
      "metadata": {
        "id": "aL33wak9hrLt"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range (0,len(dataset)):\n",
        "  if(dataset[i][1] == 0):\n",
        "    class_bach_0 += 1\n",
        "  if(dataset[i][1] == 1):\n",
        "    class_beethoven_1 += 1\n",
        "  if(dataset[i][1] == 2):\n",
        "    class_debussy_2 += 1\n",
        "  if(dataset[i][1] == 3):\n",
        "    class_scarlatti_3 += 1\n",
        "  if(dataset[i][1] == 4):\n",
        "    class_victoria_4 += 1\n",
        "print(class_bach_0, class_beethoven_1, class_debussy_2, class_scarlatti_3, class_victoria_4)"
      ],
      "metadata": {
        "id": "Hwn-ZQJMhUUR"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_bach_0\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CgH5YZZUi1px",
        "outputId": "648a6777-4316-4ef4-f28d-553191841628"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1630"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class_beethoven_1\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GyrjeRQLi8Z_",
        "outputId": "ad7b27ab-a191-4d44-e525-dbe93b61205c"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "478"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class_debussy_2\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GqfOlE35i-oW",
        "outputId": "edcc2a0c-9902-4e15-b742-0caaf9b8d1e9"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "154"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class_scarlatti_3\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5uU1OPtgjBN0",
        "outputId": "1d5689e6-36ef-4106-cd99-20103f783219"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "441"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class_victoria_4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pAYCC1MAjCUB",
        "outputId": "0dcd5122-f7d7-4082-d4dc-83d7d6aae95f"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "236"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "oversampled_dataset = dataset"
      ],
      "metadata": {
        "id": "9pQ3oDEjhdfv"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(oversampled_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U6EUCMuQhhhi",
        "outputId": "b94f0108-d538-4cf3-9dfe-cd55cc78b92c"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2939"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range (0,len(dataset)):\n",
        "  if(dataset[i][1] == 1):\n",
        "    class_beethoven_1 += 1\n",
        "    oversampled_dataset.append(dataset[i])\n",
        "  if(dataset[i][1] == 2):\n",
        "    class_debussy_2 += 1\n",
        "    oversampled_dataset.append(dataset[i])\n",
        "  if(dataset[i][1] == 3):\n",
        "    class_scarlatti_3 += 1\n",
        "    oversampled_dataset.append(dataset[i])\n",
        "  if(dataset[i][1] == 4):\n",
        "    class_victoria_4 += 1\n",
        "    oversampled_dataset.append(dataset[i])"
      ],
      "metadata": {
        "id": "yXdDhJf_hl_R"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "oversampled_dataset[2940]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gkAQD1Smh0Qf",
        "outputId": "2a759e49-ec9a-49e7-a8cd-bc265f023ce6"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([144.,  13., 191., 144.,  44., 156.,  40., 156.,  40.,  13.,  13.,\n",
              "        156.,  40., 156.,  92.,   8., 156., 156., 159.,  12.,  12.,  92.,\n",
              "         92., 125.,  12.,  88.,  80.,  41.,  78.,  12.,  92.,  41.,  60.,\n",
              "          0.,  64.,  33.,  40., 144., 144.,  30., 132.,  37.,  32.,  44.,\n",
              "         30.,  44.,  44., 177.,  44., 156.,  64., 156.,  30., 144.,  30.,\n",
              "         30.,  44.,  44.,  44.,  30.,  44.,  44.,  73.,  44.,  44.,  30.,\n",
              "        156., 151.,  68.,  79.,  77., 156., 156.,  44.,  68.,  79.,  77.,\n",
              "        156., 156., 144., 144.,  13., 191., 144.,  44., 156.,  40., 156.,\n",
              "         40.,  13.,  13., 156.,  40., 156.,  92.,   8., 156., 156., 159.,\n",
              "         12.,  12.,  12.,  28., 125.,  12.,  88.,  80.,  41.,  78.,  12.,\n",
              "         92.,  41.,  78.,  64.,  64.,  64.,  33., 144., 144., 144.,  30.,\n",
              "        132.,  37.,  32.,  44.,  30.,  44.,  44., 177.,  44., 156.,  64.,\n",
              "        156.,  30., 144.,  30.,  30.,  37.,  37.,  44.,  30.,  44.,  44.,\n",
              "         73.,  44.,  44.,  30., 156., 151.,  68.,  79.,  77., 156., 156.,\n",
              "         44.,  68.,  79.,  77., 156., 156., 144., 144.,  13., 191., 144.,\n",
              "         44., 156.,  40., 156.,  40.,  13.,  13., 156.,  40., 156.,   8.,\n",
              "         12., 156., 156.,  69.,  12.,  12.,  12.,  92., 125.,  12.,  88.,\n",
              "         80.,  41.,  78.,  12.,  92.,  41.,  78.,  64.,  64.,  64.,  33.,\n",
              "        144., 144.,  25.,  30., 132.,  37.,  32.,  44.,  30.,  44.,  44.,\n",
              "        177.,  44., 156.,  64., 156.,  30., 144.,  30.,  30.,  37.,  37.,\n",
              "         44.,  30.,  44.,  44.,  73.,  44.,  44.,  30., 156., 151.,  68.,\n",
              "         79.,  77., 156., 156.,  44.,  68.,  79.,  77., 156., 156.,  32.,\n",
              "         36.,  44., 144., 144., 144., 144., 144.]), 1)"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "class VariableLenDataset(Dataset):\n",
        "    def __init__(self, in_data):\n",
        "        self.data = [(x, y) for x, y in in_data]    \n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def max(self):\n",
        "        max = 0\n",
        "        for data, target in self.data:\n",
        "            if(len(data) > max):\n",
        "              max = len(data)\n",
        "        return max\n",
        "          \n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        seq, target = self.data[idx]\n",
        "        return seq, target"
      ],
      "metadata": {
        "id": "0eww5L0ulHY2"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_part = int(0.8 * len(dataset))\n",
        "train_size = int(0.8 * train_part)\n",
        "validation_size = train_part - train_size\n",
        "test_size = len(dataset) - train_part\n",
        "train_set, validation_set, test_set = torch.utils.data.random_split(oversampled_dataset, [train_size, validation_size, test_size])"
      ],
      "metadata": {
        "id": "cBllHadAVDa3"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
        "def collate_fn(batch, pad_value=0):\n",
        "    \"\"\"\n",
        "       data: is a list of tuples with (example, label, length)\n",
        "             where 'example' is a tensor of arbitrary shape\n",
        "             and label/length are scalars\n",
        "    \"\"\"\n",
        "    #print(batch[1])\n",
        "    #inputs = [torch.tensor(d['tokenized_input']) for d in data] #(3)\n",
        "   # labels = [d['label'] for d in data]\n",
        "    seq, target = zip(*batch)\n",
        "    inputs = [torch.tensor(x) for x in seq] #(3)\n",
        "    labels = torch.tensor(target)\n",
        "    seq_pad = pad_sequence(inputs, batch_first=True)\n",
        "    return seq_pad, labels"
      ],
      "metadata": {
        "id": "CupO78H_utNF"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(train_set, batch_size=50, shuffle=True, drop_last = True, collate_fn=collate_fn)\n",
        "test_loader = DataLoader(test_set, batch_size=50, shuffle=False, drop_last = True, collate_fn=collate_fn)\n",
        "validation_loader = DataLoader(validation_set, batch_size=50, shuffle=False, drop_last = True, collate_fn=collate_fn)"
      ],
      "metadata": {
        "id": "xk-C73Usrzbo"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_set)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zrPI8gwAqa8A",
        "outputId": "ae296926-bd77-4df6-e1b0-69d8fc272134"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2718"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(validation_set)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YVL8op_6q4V2",
        "outputId": "60e0f90a-2e49-406c-ea23-164c9d331772"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "680"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(test_set)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5bK7G2duVSiS",
        "outputId": "1fe9a9e5-58c1-40d0-b67e-dd91279390e7"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "850"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_set[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E3mWIzK3HeGd",
        "outputId": "b1d7de1c-182f-4b96-a768-37b46eb0c45d"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([ -1.,  -1.,  -1.,  -1.,   0., 148.,   1., 180., 146.,  73.,  69.,\n",
              "         92.,  60.,  47.,  12.,  12., 148.,  20.,  68., 132., 159.,  68.,\n",
              "        185., 124., 124.,  37.,  79.,  12.,  28.,  28.,  28.,  28.,  92.,\n",
              "         12.,  47.,  92.,  88., 159.,  41.,  12.,  12.,  47., 159.,  92.,\n",
              "         28.,  28.,  28.,  28.,  28.,  47.,  28.,  93.,  28.,  13.,  45.,\n",
              "        125., 157.,  77.,  78.,  47., 125., 157.,  47.,  93.,  12.,  12.,\n",
              "         47.,  47.,  28.,  12., 159.,  13.,  28.,  28.,  28.,  28.,  12.,\n",
              "         73., 124.,   5., 185., 159., 124., 124.,  12.,  12.,  45.,  15.,\n",
              "        124., 159., 124., 185.,  47.,  20.,  47.,  12., 119.,  12.,  28.,\n",
              "         47.,  12.,  13.,  28.,  28.,  28.,  28.,  47.,  13.,  28., 159.,\n",
              "         28.,  60.,  28., 159.,  12.,  12., 159., 124., 124., 159.,  92.,\n",
              "         76.,  76.,  12., 106.,  76.,  76.,  76.,  79., 159., 190.,  79.,\n",
              "        190.,  62.,  76.,  60., 124.,  30.,  44., 111., 156.,  12.,  79.,\n",
              "        124.,  12.,  45., 111., 156.,  12.,  78.,  12.,  12.,  78.,  12.,\n",
              "         28.,  13.,  78.,  79.,  28., 190.,  78.,  30., 190.,  77.,  13.,\n",
              "         94.,  76.,  92., 152.,  47.,  60., 125.,  12.,  78.,  92., 159.,\n",
              "         12.,  60., 125.,  13.,  47., 127.,  47.,  92.,  92.,  28.,  20.,\n",
              "         60.,  92.,  92., 153., 127.,  92., 158.,  47., 127.,  13.,  29.,\n",
              "        158.,  13.,  92., 158.,  28.,  47.,  28., 140.,  28.,  60., 125.,\n",
              "        157.,  44.,  45., 124.,  37., 127.,  44.,  44.,  44.,  20.,  44.,\n",
              "         44.,  88.,  47., 127., 158.,  13., 127., 125.,  44.,  78.,  92.,\n",
              "        191.,  44.,  60., 157.,  30., 127.,  44.,  47., 190.,  77., 190.,\n",
              "        156.,  69., 172.,  12., 156., 190.,  78.,  28.,  78.,  77.,  92.,\n",
              "         78., 125.,  78., 157., 127.,  60.,  92.,  79.,  13.,   6.,  93.,\n",
              "          8.,  92.,  47.,  12., 159.,  47., 172.,  28.,  12.,  12., 159.,\n",
              "         92.,  28.,  28.,  28.,  28.,  12.,  47.,  79., 159., 157.,  60.,\n",
              "         13.,   7., 190., 156.,  30., 124.,  79.,  92.,  28.,  88.,  28.,\n",
              "         73.,  28.,  41.,  28., 159.,  28., 172.,  28.,  73.,  13.,  88.,\n",
              "        125.,  12., 159.,  92., 159., 124.,  79.,  13.,  45., 159.,  92.,\n",
              "         13.,  92.,  28.,  93.,  28., 159.,  28.,   8.,  28.,  47.,  28.,\n",
              "        159.,  12.,   8.,  13.,  47.,  28.,  73.,  15.,  12., 159., 124.,\n",
              "         93., 125., 172.,  28.,  12.,  47.,  12.,  28.,  47.,  12.,  92.,\n",
              "         28.,  28.,  28.,  28.,  12.,  28.,  68., 125.,   8.,  12.,  47.,\n",
              "         47.,  12.,  73., 159.,  92.,  28.,  28.,  28.,  28.,  28.,  13.,\n",
              "         93., 125.,  28.,  13.,  28.,  12.,  12.,  12.,  73.,  67.]), 0)"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_features, train_labels = next(iter(train_loader))"
      ],
      "metadata": {
        "id": "LgrOK_VzcAbb"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_features[0].size()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AZQ9vMJ2I8xN",
        "outputId": "d1a75a0a-e0e5-4f1b-f62c-f242ff9b35c1"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([5299])"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_features[1].size()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qWvOxnubJIgU",
        "outputId": "b14870e8-8eb0-49cb-985a-074eaaf30f05"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([5299])"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTMRegressor(nn.Module):\n",
        "\n",
        "    def __init__(self, input_size, hidden_size, num_layers, out_size):\n",
        "        super().__init__()\n",
        "        self.num_layers = num_layers\n",
        "        self.hidden_size = hidden_size\n",
        "        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers)\n",
        "        self.fc = nn.Linear(hidden_size, out_size)\n",
        "        \n",
        "    def init_hidden(self, batch_size):\n",
        "        hidden = torch.zeros(self.num_layers, batch_size, self.hidden_size)\n",
        "        state = torch.zeros(self.num_layers, batch_size, self.hidden_size)\n",
        "        return hidden, state\n",
        "    \n",
        "    def forward(self, x, hidden):\n",
        "        x = torch.transpose(x, 0, 1)\n",
        "        all_outputs, hidden = self.lstm(x, hidden)\n",
        "        out = all_outputs[-1] # We are interested only in the last output\n",
        "        x = self.fc(out)\n",
        "        return x, hidden\n",
        "    \n",
        "model = LSTMRegressor(input_size=1, hidden_size = 20, num_layers = 3, out_size = 5).to(device)\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YVGv0qHQUItx",
        "outputId": "31e6fae9-4e46-4fc9-8f01-eab01a12a322"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LSTMRegressor(\n",
              "  (lstm): LSTM(1, 20, num_layers=3)\n",
              "  (fc): Linear(in_features=20, out_features=5, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "loss_fun = nn.CrossEntropyLoss()\n",
        "\n",
        "num_epochs = 20\n",
        "training_loss = 0\n",
        "validation_loss = 0\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "      #print(i, data)\n",
        "      #print(i, data)\n",
        "\n",
        "      inputs, labels = data\n",
        "      inputs = inputs.to(device).unsqueeze(2)\n",
        "      #inputs = [seq.to(device) for seq in inputs]\n",
        "      labels = labels.to(device)\n",
        "      #print(inputs)\n",
        "      hidden, state = model.init_hidden(inputs.size(0))\n",
        "      hidden, state = hidden.to(device), state.to(device)\n",
        "      preds, last_hidden = model(inputs, (hidden,state))\n",
        "      optimizer.zero_grad() \n",
        "      loss = loss_fun(preds, labels)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      training_loss += loss.item()\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "      for i, data in enumerate(validation_loader, 0):\n",
        "        inputs, labels = data\n",
        "        inputs = inputs.to(device).unsqueeze(2)\n",
        "        labels = labels.to(device)\n",
        "        #hidden, state = hidden.to(device), state.to(device)\n",
        "        preds, last_hidden = model(inputs, (hidden,state))\n",
        "        loss = loss_fun(preds, labels)\n",
        "      \n",
        "        validation_loss += loss.item()\n",
        "\n",
        "    if epoch % 5 == 0:\n",
        "      print(f\"Epoch: {epoch}, training loss: {training_loss/1:.3}, validation loss: {validation_loss/1:.3}\")\n",
        "      training_loss = 0\n",
        "      validation_loss = 0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GCOKIvDnUhVv",
        "outputId": "3ca7ce53-2dbe-43b7-ea4c-638daa31b5cc"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0, training loss: 81.3, validation loss: 19.0\n",
            "Epoch: 5, training loss: 3.95e+02, validation loss: 94.8\n",
            "Epoch: 10, training loss: 4.02e+02, validation loss: 1.04e+02\n",
            "Epoch: 15, training loss: 3.97e+02, validation loss: 95.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "correct_pred = {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}\n",
        "total_pred = {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}\n",
        "correct_pred.items()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g-76bXTKhFWL",
        "outputId": "16d9bf7c-e2bb-43bb-d7fd-ba36119b455d"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_items([(0, 0), (1, 0), (2, 0), (3, 0), (4, 0)])"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "acc_sum = 0\n",
        "with torch.no_grad():\n",
        "    for i, data in enumerate(test_loader, 0):\n",
        "        inputs, labels = data\n",
        "        inputs = inputs.to(device).unsqueeze(2)\n",
        "        labels = labels.to(device)\n",
        "        #hidden, state = hidden.to(device), state.to(device)\n",
        "        preds, last_hidden = model(inputs, (hidden,state))\n",
        "        _, predictions = torch.max(preds, 1)\n",
        "        for label, prediction in zip(labels, predictions):\n",
        "          if label == prediction:\n",
        "              correct_pred[label.item()] += 1\n",
        "          total_pred[label.item()] += 1\n",
        "\n"
      ],
      "metadata": {
        "id": "ygsyx9cHRlWl"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "correct_pred.items()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZovO2YQZiEFm",
        "outputId": "d3b8d719-88c5-4ff8-a3af-c8ec8a54b25d"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_items([(0, 323), (1, 17), (2, 0), (3, 0), (4, 0)])"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total_pred.items()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oMezW3SEiHQ-",
        "outputId": "40ea5e1b-4395-43b2-e41a-ee1498000477"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_items([(0, 326), (1, 197), (2, 50), (3, 184), (4, 93)])"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "acc_sum = 0\n",
        "for classname, correct_count in correct_pred.items():\n",
        "    print(\"Class: {}, correct predictions: {}, total_predictions {}\".format(classname, correct_count, total_pred[classname]))\n",
        "    accuracy = 100 * float(correct_count) / total_pred[classname]\n",
        "    acc_sum += accuracy\n",
        "    print(\"Accuracy for class {} is: {:.1f} %\".format(classname, \n",
        "                                                   accuracy))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OSpH9xo_hzcd",
        "outputId": "307dd4ef-b3b3-4073-c189-50e09d05ab04"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class: 0, correct predictions: 323, total_predictions 326\n",
            "Accuracy for class 0 is: 99.1 %\n",
            "Class: 1, correct predictions: 17, total_predictions 197\n",
            "Accuracy for class 1 is: 8.6 %\n",
            "Class: 2, correct predictions: 0, total_predictions 50\n",
            "Accuracy for class 2 is: 0.0 %\n",
            "Class: 3, correct predictions: 0, total_predictions 184\n",
            "Accuracy for class 3 is: 0.0 %\n",
            "Class: 4, correct predictions: 0, total_predictions 93\n",
            "Accuracy for class 4 is: 0.0 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "acc_sum"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pOOxBipmjAUi",
        "outputId": "9c0b6604-6754-4ce3-fe8e-779014f0dd90"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "107.70919622559248"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "acc_average_all_classes = acc_sum / len(correct_pred)\n",
        "acc_average_all_classes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vmL_kvuVitA0",
        "outputId": "93f0f720-3ea6-4af0-d28c-69c6a981bfeb"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "21.541839245118496"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = LSTMRegressor(input_size=1, hidden_size = 20, num_layers = 2, out_size = 5).to(device)\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1oDAKCe4mTZX",
        "outputId": "aa5561fa-5baf-4de4-bd0a-afb27b78dab7"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LSTMRegressor(\n",
              "  (lstm): LSTM(1, 20, num_layers=2)\n",
              "  (fc): Linear(in_features=20, out_features=5, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "loss_fun = nn.CrossEntropyLoss()\n",
        "\n",
        "num_epochs = 100\n",
        "training_loss = 0\n",
        "validation_loss = 0\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "      #print(i, data)\n",
        "      #print(i, data)\n",
        "\n",
        "      inputs, labels = data\n",
        "      inputs = inputs.to(device).unsqueeze(2)\n",
        "      #inputs = [seq.to(device) for seq in inputs]\n",
        "      labels = labels.to(device)\n",
        "      #print(inputs)\n",
        "      hidden, state = model.init_hidden(inputs.size(0))\n",
        "      hidden, state = hidden.to(device), state.to(device)\n",
        "      preds, last_hidden = model(inputs, (hidden,state))\n",
        "      optimizer.zero_grad() \n",
        "      loss = loss_fun(preds, labels)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      training_loss += loss.item()\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "      for i, data in enumerate(validation_loader, 0):\n",
        "        inputs, labels = data\n",
        "        inputs = inputs.to(device).unsqueeze(2)\n",
        "        labels = labels.to(device)\n",
        "        #hidden, state = hidden.to(device), state.to(device)\n",
        "        preds, last_hidden = model(inputs, (hidden,state))\n",
        "        loss = loss_fun(preds, labels)\n",
        "      \n",
        "        validation_loss += loss.item()\n",
        "\n",
        "    if epoch % 5 == 0:\n",
        "      print(f\"Epoch: {epoch}, training loss: {training_loss/1:.3}, validation loss: {validation_loss/1:.3}\")\n",
        "      training_loss = 0\n",
        "      validation_loss = 0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eCBmDTtTmTgm",
        "outputId": "2fc01453-b297-42c9-a98d-cb067cf3a1ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0, training loss: 76.9, validation loss: 18.7\n",
            "Epoch: 5, training loss: 3.84e+02, validation loss: 93.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "correct_pred = {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}\n",
        "total_pred = {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}\n",
        "correct_pred.items()"
      ],
      "metadata": {
        "id": "_n2AtV9imao_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc_sum = 0\n",
        "with torch.no_grad():\n",
        "    for i, data in enumerate(test_loader, 0):\n",
        "        inputs, labels = data\n",
        "        inputs = inputs.to(device).unsqueeze(2)\n",
        "        labels = labels.to(device)\n",
        "        #hidden, state = hidden.to(device), state.to(device)\n",
        "        preds, last_hidden = model(inputs, (hidden,state))\n",
        "        _, predictions = torch.max(preds, 1)\n",
        "        for label, prediction in zip(labels, predictions):\n",
        "          if label == prediction:\n",
        "              correct_pred[label.item()] += 1\n",
        "          total_pred[label.item()] += 1\n",
        "\n"
      ],
      "metadata": {
        "id": "yTV123k_wtYl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc_sum = 0\n",
        "for classname, correct_count in correct_pred.items():\n",
        "    print(\"Class: {}, correct predictions: {}, total_predictions {}\".format(classname, correct_count, total_pred[classname]))\n",
        "    accuracy = 100 * float(correct_count) / total_pred[classname]\n",
        "    acc_sum += accuracy\n",
        "    print(\"Accuracy for class {} is: {:.1f} %\".format(classname, \n",
        "                                                   accuracy))"
      ],
      "metadata": {
        "id": "sT7Q-rX8mc7N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc_average_all_classes = acc_sum / len(correct_pred)\n",
        "acc_average_all_classes"
      ],
      "metadata": {
        "id": "3qXioiVymemM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}